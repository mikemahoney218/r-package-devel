From edwwe|2020 @end|ng |rom gm@||@com  Mon Oct  3 17:03:20 2022
From: edwwe|2020 @end|ng |rom gm@||@com (Edward Wei)
Date: Mon, 3 Oct 2022 08:03:20 -0700
Subject: [R-pkg-devel] Unable to create manual
In-Reply-To: <20220926220141.71df28e0@Tarkus>
References: <CAEf_eRCTaa5Xnv6TkHX=Jncqv+Fu7PMTM=_w7WLFj9SDGVKm5g@mail.gmail.com>
 <a51aa30d-bff0-2824-fd6f-948a70975e06@gmail.com>
 <a325c931-4074-ca48-5d0a-42f410429eff@statistik.tu-dortmund.de>
 <CAEf_eRD7qyzRiVDrX5_CA-hEQ7wj-G+3Ku-=+2X2t=+Ai+g+aw@mail.gmail.com>
 <3275b3cb-33b1-3c2b-b86d-7ca73c8d6cb9@gmail.com>
 <CAEf_eRCUs-zRqdkPLnFMUB0Am6+=g+=DjcGsZ==Biu62MNgjhQ@mail.gmail.com>
 <20220926220141.71df28e0@Tarkus>
Message-ID: <CAEf_eRBiiSdAequnQWD9OMbP1Z=NFoPBtKQfzGG+X65b8d+Mew@mail.gmail.com>

Hello Ivan.

The Does list.files(pattern = 'utils|Rout\\.fail') gave me something like
an empty string.

So after getting some in-person help on this issue, the key to resolving
this error was explicitly defining the environmental variables in the
console as:

set
PDFLATEX=C:\Users\edmon\AppData\Local\Programs\MiKTeX\miktex\bin\x64\pdflatex



set
MAKEINDEX=C:\Users\edmon\AppData\Local\Programs\MiKTeX\miktex\bin\x64\makeindex


The makeindex was a package I was apparently missing for MikTex and I had
to download it as part of generating the manual.


I would have to set up the environmental variables every time that R got
started in order for the R CMD check to run smoothly.


Best regards,




On Mon, Sep 26, 2022 at 12:01 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Mon, 26 Sep 2022 10:50:01 -0700
> Edward Wei <edwwei2020 at gmail.com> wrote:
>
> > 1. Where do I run "make check"?
>
> In the directory where R is built from source. If you're using a binary
> build of R, this isn't applicable.
>
> > 3. I get this back when I run the "tools::testInstalledPackages(scope
> > = "base")" on my RGUI.
> >
> > Error: testing 'utils' failed
> >
> > Where may I find the error log for this?
>
> testInstalledPackages() creates output files in the current directory.
> Does list.files(pattern = 'utils|Rout\\.fail') give you anything useful?
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From etie@@e@come m@iii@g oii u@iv-eiiiei@ir  Tue Oct  4 12:25:57 2022
From: etie@@e@come m@iii@g oii u@iv-eiiiei@ir (etie@@e@come m@iii@g oii u@iv-eiiiei@ir)
Date: Tue, 4 Oct 2022 12:25:57 +0200 (CEST)
Subject: [R-pkg-devel] 
 NOTE checking for detritus in the temp directory on windows
In-Reply-To: <CAFDcVCQNaP8=iLPG+Vk4vfEN1Y5zfeabca8Qnov5ZomsGLwsZA@mail.gmail.com>
References: <1624161329.20817062.1664440955959.JavaMail.zimbra@ifsttar.fr>
 <CAFDcVCQNaP8=iLPG+Vk4vfEN1Y5zfeabca8Qnov5ZomsGLwsZA@mail.gmail.com>
Message-ID: <1104744221.26257047.1664879157504.JavaMail.zimbra@ifsttar.fr>

Hi,

Thanks a lot Henrik for your detailed response, the problem was the one you suspected a "plan(mutlisession)" that was not correctly closed. And following your advice I was able to reproduce it on winbuilder.

So thanks again for your help!

Best regards, 

Etienne


Etienne C?me, @comeetie
Charg? de Recherche
Universit? Gustave Eiffel
GRETTIA/COSYS
Tel : 01 81 66 87 18
Web : http://www.comeetie.fr

----- Mail original -----
De: "Henrik Bengtsson" <henrik.bengtsson at gmail.com>
?: "etienne come" <etienne.come at univ-eiffel.fr>
Cc: "r-package-devel" <r-package-devel at r-project.org>
Envoy?: Vendredi 30 Septembre 2022 17:19:03
Objet: Re: [R-pkg-devel] NOTE checking for detritus in the temp directory on windows

Hi.

> * checking for detritus in the temp directory ... NOTE
> Found the following files/directories:
> 'Rscript306c1f1adf1' 'Rscript3fb41f1adf1'

Whenever seeing detritus files with name Rscript<hexcode> like these,
it's a strong suggestion that parallel workers on MS Windows are
involved.  More precisely, each of them is from a separate PSOCK
cluster node worker typically launched by parallel::makeCluster().
When such workers are launched in example code, unit tests, or
vignettes those files are created by R itself when running on MS
Windows.  If the workers are not properly shutdown (e.g. forgetting to
call parallel::stopCluster()), those files are left behind, and 'R CMD
check' will detect them.

Now, from experience, but neither fully investigated not understood
yet, it *might* be that even if one calls parallel::stopCluster() at
the end of examples, unit tests, or vignettes, it might be that there
is still a race condition where the parallel workers are still in the
process of shutting down when 'R CMD check' is checking for detritus
files.  If that is the case, then it might be sporadic and tricky to
reproduce this problem.  This has happened to me exactly once. I'm
saying this, only in case you're struggle to reproduce it, but my
guess is that this is *not* the case here. Please see below for
options how to reproduce.

Now, I see you're using 'future' for parallelization.  Because of
this, I suspect you use plan(multisession), which launches parallel
PSOCK workers like parallel::makeCluster().  To shut down those
workers at the end, call plan(sequential).  My guess is that this is
your problem.  Before you do that, I would make sure you can reproduce
the problem first - see below.

> I did not manage to reproduce it with Rhub and github action.

1. Looking at your
https://github.com/comeetie/greed/blob/master/.github/workflows/R-CMD-check.yaml,
I see you're not checking with **R-devel** on MS Windows. I suggest
you add that and too see if you can reproduce it there.  You could
also add an explicit `env: _R_CHECK_THINGS_IN_TEMP_DIR_: true` just in
case (but I'd guess --as-cran does this).

2. Similarly, did you make sure to test with R-devel on MS Windows on R-hub?

3. Did you try with R-devel on the win-builder service?

For your future needs (pun not intended), I would make sure you can
reproduce the problem before trying to fix it.

Hope this helps,

Henrik

On Fri, Sep 30, 2022 at 12:14 AM <etienne.come at univ-eiffel.fr> wrote:
>
> Dear all,
>
> I'm getting the following Note for CRAN pre-tests (for package greed https://github.com/comeetie/greed) :
>
> * checking for detritus in the temp directory ... NOTE
> Found the following files/directories:
> 'Rscript306c1f1adf1' 'Rscript3fb41f1adf1'
>
> this note only appears on windows :
>
> * using R Under development (unstable) (2022-09-26 r82921 ucrt)
> * using platform: x86_64-w64-mingw32 (64-bit)
>
> The full pretest logs are located at https://win-builder.r-project.org/incoming_pretest/greed_0.6.1_20220927_163632/Windows/00check.log
>
> I did not manage to reproduce it with Rhub and github action.
>
> I've seen other questions on the mailing list about "detritus" but the root causes seems to be different in my case since i did not open a navigator and i did not create
> files or folders in my tests or vignettes. Any hint on how to solve this note will be welcome.
>
> Thanks a lot
>
> Etienne
>
>
> Etienne C?me, @comeetie
> Charg? de Recherche
> Universit? Gustave Eiffel
> GRETTIA/COSYS
> Tel : 01 81 66 87 18
> Web : http://www.comeetie.fr
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From v|ncentv@nhee@ @end|ng |rom gm@||@com  Tue Oct  4 16:46:03 2022
From: v|ncentv@nhee@ @end|ng |rom gm@||@com (Vincent van Hees)
Date: Tue, 4 Oct 2022 16:46:03 +0200
Subject: [R-pkg-devel] Guidance on splitting up an R package?
Message-ID: <CALnEB17ExKcv=+EH4NycFFta+jaF0N1FjbfCphttK=cnBdKgow@mail.gmail.com>

Dear all,

I am looking for guidance (blog posts / books / people with expertise) on
how to split up an R package that has grown a lot in complexity and size.
To make it worthwhile, the split needs to ease the maintenance and ongoing
development.

Here are my quick reflections on it:
1. Where possible try to preserve the consistency of the original R
package. So, spin-off packages should ideally become helper-packages to the
original package and tests need to be in place to ensure compatibility of
the original R package is preserved.
2. Keep similar functionality together. For example, a function to read
files does not have to be in the same package as a function to plot the
data, but a function to adjust the color coding of the plots should be
stored near the other plotting functions.
3. Try to isolate external dependencies. For example, if dependency Y
changes I ideally only have to worry about updating one of my R packages to
it instead of several.

I am wondering whether anyone else has ever made a more elaborate mapping
of do's and don'ts when it comes to splitting up an R package or any
software for that matter?

Vincent

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Oct  4 17:45:58 2022
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 4 Oct 2022 17:45:58 +0200
Subject: [R-pkg-devel] Guidance on splitting up an R package?
In-Reply-To: <CALnEB17ExKcv=+EH4NycFFta+jaF0N1FjbfCphttK=cnBdKgow@mail.gmail.com>
References: <CALnEB17ExKcv=+EH4NycFFta+jaF0N1FjbfCphttK=cnBdKgow@mail.gmail.com>
Message-ID: <CAJuCY5y8rxenG8=tHjQNQvHgp_wKJ5Q_JdN5++t8AuuWz62-Og@mail.gmail.com>

Dear Vincent,

Have a look at the spatstat package which was split into several smaller
packages (https://github.com/spatstat/spatstat). Maybe the maintainers of
that package can share some insights.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 4 okt. 2022 om 16:46 schreef Vincent van Hees <
vincentvanhees at gmail.com>:

> Dear all,
>
> I am looking for guidance (blog posts / books / people with expertise) on
> how to split up an R package that has grown a lot in complexity and size.
> To make it worthwhile, the split needs to ease the maintenance and ongoing
> development.
>
> Here are my quick reflections on it:
> 1. Where possible try to preserve the consistency of the original R
> package. So, spin-off packages should ideally become helper-packages to the
> original package and tests need to be in place to ensure compatibility of
> the original R package is preserved.
> 2. Keep similar functionality together. For example, a function to read
> files does not have to be in the same package as a function to plot the
> data, but a function to adjust the color coding of the plots should be
> stored near the other plotting functions.
> 3. Try to isolate external dependencies. For example, if dependency Y
> changes I ideally only have to worry about updating one of my R packages to
> it instead of several.
>
> I am wondering whether anyone else has ever made a more elaborate mapping
> of do's and don'ts when it comes to splitting up an R package or any
> software for that matter?
>
> Vincent
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From |gor|@|tu| @end|ng |rom gm@||@com  Tue Oct  4 20:29:54 2022
From: |gor|@|tu| @end|ng |rom gm@||@com (Igor L)
Date: Tue, 4 Oct 2022 15:29:54 -0300
Subject: [R-pkg-devel] How to decrease time to import files in xlsx format?
Message-ID: <CAHGVjr=K9YbwVhEhxq_=9v_uxkT5FXzqhoyomdPWKn_erDsvDA@mail.gmail.com>

Hello all,

I'm developing an R package that basically downloads, imports, cleans and
merges nine files in xlsx format updated monthly from a public institution.

The problem is that importing files in xlsx format is time consuming.

My initial idea was to parallelize the execution of the read_xlsx function
according to the number of cores in the user's processor, but apparently it
didn't make much difference, since when trying to parallelize it the
execution time went from 185.89 to 184.12 seconds:

# not parallelized code
y <- purrr::map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
               readxl::read_excel, sheet = 1, skip = 4, col_types =
c(rep('text', 30)))

# parallelized code
plan(strategy = future::multicore(workers = 4))
y <- furrr::future_map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
                             readxl::read_excel, sheet = 1, skip = 4,
col_types = c(rep('text', 30)))

 Any suggestions to reduce the import processing time?

Thanks in advance!

-- 
*Igor Laltuf Marques*
Economist (UFF)
Master in Urban and Regional Planning (IPPUR-UFRJ)
Researcher at ETTERN and CiDMob
https://igorlaltuf.github.io/

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Oct  4 21:39:08 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 4 Oct 2022 22:39:08 +0300
Subject: [R-pkg-devel] 
 How to decrease time to import files in xlsx format?
In-Reply-To: <CAHGVjr=K9YbwVhEhxq_=9v_uxkT5FXzqhoyomdPWKn_erDsvDA@mail.gmail.com>
References: <CAHGVjr=K9YbwVhEhxq_=9v_uxkT5FXzqhoyomdPWKn_erDsvDA@mail.gmail.com>
Message-ID: <20221004223908.0f9894b7@Tarkus>

On Tue, 4 Oct 2022 15:29:54 -0300
Igor L <igorlaltuf at gmail.com> wrote:

> The problem is that importing files in xlsx format is time consuming.

Do the openxlsx or XLConnect packages fare any better?

> plan(strategy = future::multicore(workers = 4))

As far as I understand the documentation, multicore only works on
POSIX-compatible operating systems when not running under RStudio (and
even then, some macOS APIs may be not fork()-safe). Which operating
system are you running? Does it get any better if you use
future::multisession?

Have you tried profiling the code? Do you see it using 100% of one
core in some kind of task manager?

-- 
Best regards,
Ivan


From ||@t@ @end|ng |rom reve||e@net  Tue Oct  4 21:42:19 2022
From: ||@t@ @end|ng |rom reve||e@net (William Revelle)
Date: Tue, 4 Oct 2022 14:42:19 -0500
Subject: [R-pkg-devel] Guidance on splitting up an R package?
In-Reply-To: <CALnEB17ExKcv=+EH4NycFFta+jaF0N1FjbfCphttK=cnBdKgow@mail.gmail.com>
References: <CALnEB17ExKcv=+EH4NycFFta+jaF0N1FjbfCphttK=cnBdKgow@mail.gmail.com>
Message-ID: <5AD2FF42-DEBA-4907-8DFC-3A7D6D7FB45D@revelle.net>

In 2019, I split psych into psych and psychTools to meet the 5MB space restriction.  I moved several of vignettes, data sets, and a few helper functions over to psychTools. This mainly allowed for more vignettes but also allows me to add new data sets to psychTools without needing to recompile psych.   This is discussed in the news file for psych and psychTools.

Bill




> On Oct 4, 2022, at 9:46 AM, Vincent van Hees <vincentvanhees at gmail.com> wrote:
> 
> Dear all,
> 
> I am looking for guidance (blog posts / books / people with expertise) on
> how to split up an R package that has grown a lot in complexity and size.
> To make it worthwhile, the split needs to ease the maintenance and ongoing
> development.
> 
> Here are my quick reflections on it:
> 1. Where possible try to preserve the consistency of the original R
> package. So, spin-off packages should ideally become helper-packages to the
> original package and tests need to be in place to ensure compatibility of
> the original R package is preserved.
> 2. Keep similar functionality together. For example, a function to read
> files does not have to be in the same package as a function to plot the
> data, but a function to adjust the color coding of the plots should be
> stored near the other plotting functions.
> 3. Try to isolate external dependencies. For example, if dependency Y
> changes I ideally only have to worry about updating one of my R packages to
> it instead of several.
> 
> I am wondering whether anyone else has ever made a more elaborate mapping
> of do's and don'ts when it comes to splitting up an R package or any
> software for that matter?
> 
> Vincent
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Oct  4 21:58:27 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 04 Oct 2022 12:58:27 -0700
Subject: [R-pkg-devel] 
 How to decrease time to import files in xlsx format?
In-Reply-To: <CAHGVjr=K9YbwVhEhxq_=9v_uxkT5FXzqhoyomdPWKn_erDsvDA@mail.gmail.com>
References: <CAHGVjr=K9YbwVhEhxq_=9v_uxkT5FXzqhoyomdPWKn_erDsvDA@mail.gmail.com>
Message-ID: <802EE163-77AE-48A3-987F-3F01DFB452A8@dcn.davis.ca.us>

It looks like you are reading directly from URLs? How do you know the delay is not network I/O delay?

Parallel computation is not a panacea. It allows tasks _that are CPU-bound_ to get through the CPU-intensive work faster. You need to be certain that your tasks actually can benefit from parallelism before using it... there is a significant overhead and added complexity to using parallel processing that will lead to SLOWER processing if mis-used.

On October 4, 2022 11:29:54 AM PDT, Igor L <igorlaltuf at gmail.com> wrote:
>Hello all,
>
>I'm developing an R package that basically downloads, imports, cleans and
>merges nine files in xlsx format updated monthly from a public institution.
>
>The problem is that importing files in xlsx format is time consuming.
>
>My initial idea was to parallelize the execution of the read_xlsx function
>according to the number of cores in the user's processor, but apparently it
>didn't make much difference, since when trying to parallelize it the
>execution time went from 185.89 to 184.12 seconds:
>
># not parallelized code
>y <- purrr::map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
>               readxl::read_excel, sheet = 1, skip = 4, col_types =
>c(rep('text', 30)))
>
># parallelized code
>plan(strategy = future::multicore(workers = 4))
>y <- furrr::future_map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
>                             readxl::read_excel, sheet = 1, skip = 4,
>col_types = c(rep('text', 30)))
>
> Any suggestions to reduce the import processing time?
>
>Thanks in advance!
>

-- 
Sent from my phone. Please excuse my brevity.


From john@m@h@rro|d @end|ng |rom gm@||@com  Wed Oct  5 14:32:10 2022
From: john@m@h@rro|d @end|ng |rom gm@||@com (John Harrold)
Date: Wed, 5 Oct 2022 05:32:10 -0700
Subject: [R-pkg-devel] CRAN package isoband and its reverse dependencies
Message-ID: <CANAiAiWY8VOz785QgrSDG4GT=kfO09j8CMAMJVHyL9o8oyjvdw@mail.gmail.com>

Howdy Folks,

I got a message from CRAN today telling me that I have a strong reverse
dependency on the isoband package. But I'm not alone! It look like more
than 4700 other packages also have a strong dependency on this. Is there
some organized effort to deal with this?

Thanks
John

	[[alternative HTML version deleted]]


From @|ngm@nn @end|ng |rom gm@||@com  Wed Oct  5 14:34:59 2022
From: @|ngm@nn @end|ng |rom gm@||@com (Henrik Singmann)
Date: Wed, 5 Oct 2022 13:34:59 +0100
Subject: [R-pkg-devel] CRAN package isoband and its reverse dependencies
In-Reply-To: <CANAiAiWY8VOz785QgrSDG4GT=kfO09j8CMAMJVHyL9o8oyjvdw@mail.gmail.com>
References: <CANAiAiWY8VOz785QgrSDG4GT=kfO09j8CMAMJVHyL9o8oyjvdw@mail.gmail.com>
Message-ID: <CA+rDMK+r5TO+MTeKjCGOO-eF3LgsEAfxxZNoJ__u-wq1YCqJ7w@mail.gmail.com>

Hi John,

I think the short answer is yes, see the discussion on their GitHub:
https://github.com/wilkelab/isoband/issues/31
See also: https://github.com/tidyverse/ggplot2/issues/5006

Best,
Henrik

Am Mi., 5. Okt. 2022 um 13:32 Uhr schrieb John Harrold
<john.m.harrold at gmail.com>:
>
> Howdy Folks,
>
> I got a message from CRAN today telling me that I have a strong reverse
> dependency on the isoband package. But I'm not alone! It look like more
> than 4700 other packages also have a strong dependency on this. Is there
> some organized effort to deal with this?
>
> Thanks
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel



-- 
Dr. Henrik Singmann
Lecturer, Experimental Psychology
University College London (UCL), UK
http://singmann.org


From @c @end|ng |rom |mb|@un|-|re|burg@de  Wed Oct  5 14:39:48 2022
From: @c @end|ng |rom |mb|@un|-|re|burg@de (Guido Schwarzer)
Date: Wed, 5 Oct 2022 14:39:48 +0200
Subject: [R-pkg-devel] CRAN package isoband and its reverse dependencies
In-Reply-To: <CANAiAiWY8VOz785QgrSDG4GT=kfO09j8CMAMJVHyL9o8oyjvdw@mail.gmail.com>
References: <CANAiAiWY8VOz785QgrSDG4GT=kfO09j8CMAMJVHyL9o8oyjvdw@mail.gmail.com>
Message-ID: <bcfdba01-a9ce-d149-06c2-d523785461cc@imbi.uni-freiburg.de>

Am 05.10.22 um 14:32 schrieb John Harrold:

> Howdy Folks,
>
> I got a message from CRAN today telling me that I have a strong reverse
> dependency on the isoband package. But I'm not alone! It look like more
> than 4700 other packages also have a strong dependency on this. Is there
> some organized effort to deal with this?

R package ggplot2 imports isoband which resulted in the very large 
number of strong dependencies.

For my own R packages I could move ggplot2 from Imports to Suggests, 
however, I hope that I can simply wait this out.

Best,

Guido


From |gor|@|tu| @end|ng |rom gm@||@com  Wed Oct  5 14:52:12 2022
From: |gor|@|tu| @end|ng |rom gm@||@com (Igor L)
Date: Wed, 5 Oct 2022 09:52:12 -0300
Subject: [R-pkg-devel] 
 How to decrease time to import files in xlsx format?
In-Reply-To: <802EE163-77AE-48A3-987F-3F01DFB452A8@dcn.davis.ca.us>
References: <CAHGVjr=K9YbwVhEhxq_=9v_uxkT5FXzqhoyomdPWKn_erDsvDA@mail.gmail.com>
 <802EE163-77AE-48A3-987F-3F01DFB452A8@dcn.davis.ca.us>
Message-ID: <CAHGVjrmO1a-+F4z0s986y2U=yNqUQhGpgvRRShpge6t2gprLOQ@mail.gmail.com>

According to my internet research, it looks like readxl is the fastest
package.

The profvis package indicated that the bottleneck is indeed in importing
the files.

My processor has six cores, but when I use four of them the computer
crashes completely. When I use three processors, it's still usable. So I
did one more benchmark comparing for loop, map_dfr and future_map_dfr (with
multisession and three cores).

After the benchmark was run 10 times, the result was:

             expr                  min          lq           mean
 median        uq      max neval
     import_for()        140.9940 147.9722 160.7229 155.6459 172.4661
199.1059    10
 import_map_dfr()   161.6707 339.6769 480.5760 567.8389 643.8895 666.0726
 10
   import_furrr()        112.1374 116.4301 127.5976 129.0067 137.9179
140.8632    10

For me it is proven that using the furrr package is the best solution in
this case, but what would explain so much difference with map_dfr?

Em ter., 4 de out. de 2022 ?s 16:58, Jeff Newmiller <
jdnewmil at dcn.davis.ca.us> escreveu:

> It looks like you are reading directly from URLs? How do you know the
> delay is not network I/O delay?
>
> Parallel computation is not a panacea. It allows tasks _that are
> CPU-bound_ to get through the CPU-intensive work faster. You need to be
> certain that your tasks actually can benefit from parallelism before using
> it... there is a significant overhead and added complexity to using
> parallel processing that will lead to SLOWER processing if mis-used.
>
> On October 4, 2022 11:29:54 AM PDT, Igor L <igorlaltuf at gmail.com> wrote:
> >Hello all,
> >
> >I'm developing an R package that basically downloads, imports, cleans and
> >merges nine files in xlsx format updated monthly from a public
> institution.
> >
> >The problem is that importing files in xlsx format is time consuming.
> >
> >My initial idea was to parallelize the execution of the read_xlsx function
> >according to the number of cores in the user's processor, but apparently
> it
> >didn't make much difference, since when trying to parallelize it the
> >execution time went from 185.89 to 184.12 seconds:
> >
> ># not parallelized code
> >y <- purrr::map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
> >               readxl::read_excel, sheet = 1, skip = 4, col_types =
> >c(rep('text', 30)))
> >
> ># parallelized code
> >plan(strategy = future::multicore(workers = 4))
> >y <- furrr::future_map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
> >                             readxl::read_excel, sheet = 1, skip = 4,
> >col_types = c(rep('text', 30)))
> >
> > Any suggestions to reduce the import processing time?
> >
> >Thanks in advance!
> >
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From h@w|ckh@m @end|ng |rom gm@||@com  Wed Oct  5 14:56:52 2022
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Wed, 5 Oct 2022 07:56:52 -0500
Subject: [R-pkg-devel] CRAN package isoband and its reverse dependencies
In-Reply-To: <CANAiAiWY8VOz785QgrSDG4GT=kfO09j8CMAMJVHyL9o8oyjvdw@mail.gmail.com>
References: <CANAiAiWY8VOz785QgrSDG4GT=kfO09j8CMAMJVHyL9o8oyjvdw@mail.gmail.com>
Message-ID: <CABdHhvEJoKP+vxr8KsMBCOk3z=HUsaX4K_v2ZhZZSTaHysLo6w@mail.gmail.com>

Yes, we will make sure that this is fixed ASAP. There is no need to worry.

Hadley

On Wed, Oct 5, 2022 at 7:32 AM John Harrold <john.m.harrold at gmail.com> wrote:
>
> Howdy Folks,
>
> I got a message from CRAN today telling me that I have a strong reverse
> dependency on the isoband package. But I'm not alone! It look like more
> than 4700 other packages also have a strong dependency on this. Is there
> some organized effort to deal with this?
>
> Thanks
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel



-- 
http://hadley.nz


From d|ego|coe|ho @end|ng |rom gm@||@com  Wed Oct  5 15:13:56 2022
From: d|ego|coe|ho @end|ng |rom gm@||@com (=?UTF-8?Q?Diego_de_Freitas_Co=C3=AAlho?=)
Date: Wed, 5 Oct 2022 10:13:56 -0300
Subject: [R-pkg-devel] 
 How to decrease time to import files in xlsx format?
In-Reply-To: <CAHGVjrmO1a-+F4z0s986y2U=yNqUQhGpgvRRShpge6t2gprLOQ@mail.gmail.com>
References: <CAHGVjr=K9YbwVhEhxq_=9v_uxkT5FXzqhoyomdPWKn_erDsvDA@mail.gmail.com>
 <802EE163-77AE-48A3-987F-3F01DFB452A8@dcn.davis.ca.us>
 <CAHGVjrmO1a-+F4z0s986y2U=yNqUQhGpgvRRShpge6t2gprLOQ@mail.gmail.com>
Message-ID: <CAMCrwUMMpDuDNJL=DmVD3C3r1fbbVPPbf+0qKRa062-tgKxYxA@mail.gmail.com>

Hey Igor,

I have been dealing with *CSV*/*XLSX* files from time to time and depending
on the size of those files you are mentioning, 180 seconds isn't really
that much.
From my experience, *vroom *is the fastest I've encountered but it deals
with *CSV* files (I can support its usage for up to 8gb size files).
If you have the option to import CSVs instead, you should give it a try.

Other than that there are several other factors to be considered, such as
memory and disk read/write capabilities.
And again, it is just 180 seconds so just suggest the user go get a cup of
coffee :)

Best,
Diego

On Wed, 5 Oct 2022 at 10:02, Igor L <igorlaltuf at gmail.com> wrote:

> According to my internet research, it looks like readxl is the fastest
> package.
>
> The profvis package indicated that the bottleneck is indeed in importing
> the files.
>
> My processor has six cores, but when I use four of them the computer
> crashes completely. When I use three processors, it's still usable. So I
> did one more benchmark comparing for loop, map_dfr and future_map_dfr (with
> multisession and three cores).
>
> After the benchmark was run 10 times, the result was:
>
>              expr                  min          lq           mean
>  median        uq      max neval
>      import_for()        140.9940 147.9722 160.7229 155.6459 172.4661
> 199.1059    10
>  import_map_dfr()   161.6707 339.6769 480.5760 567.8389 643.8895 666.0726
>  10
>    import_furrr()        112.1374 116.4301 127.5976 129.0067 137.9179
> 140.8632    10
>
> For me it is proven that using the furrr package is the best solution in
> this case, but what would explain so much difference with map_dfr?
>
> Em ter., 4 de out. de 2022 ?s 16:58, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> escreveu:
>
> > It looks like you are reading directly from URLs? How do you know the
> > delay is not network I/O delay?
> >
> > Parallel computation is not a panacea. It allows tasks _that are
> > CPU-bound_ to get through the CPU-intensive work faster. You need to be
> > certain that your tasks actually can benefit from parallelism before
> using
> > it... there is a significant overhead and added complexity to using
> > parallel processing that will lead to SLOWER processing if mis-used.
> >
> > On October 4, 2022 11:29:54 AM PDT, Igor L <igorlaltuf at gmail.com> wrote:
> > >Hello all,
> > >
> > >I'm developing an R package that basically downloads, imports, cleans
> and
> > >merges nine files in xlsx format updated monthly from a public
> > institution.
> > >
> > >The problem is that importing files in xlsx format is time consuming.
> > >
> > >My initial idea was to parallelize the execution of the read_xlsx
> function
> > >according to the number of cores in the user's processor, but apparently
> > it
> > >didn't make much difference, since when trying to parallelize it the
> > >execution time went from 185.89 to 184.12 seconds:
> > >
> > ># not parallelized code
> > >y <- purrr::map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
> > >               readxl::read_excel, sheet = 1, skip = 4, col_types =
> > >c(rep('text', 30)))
> > >
> > ># parallelized code
> > >plan(strategy = future::multicore(workers = 4))
> > >y <- furrr::future_map_dfr(paste0(dir.temp, '/', lista.arquivos.locais),
> > >                             readxl::read_excel, sheet = 1, skip = 4,
> > >col_types = c(rep('text', 30)))
> > >
> > > Any suggestions to reduce the import processing time?
> > >
> > >Thanks in advance!
> > >
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From @|ex@ndre@court|o| @end|ng |rom gm@||@com  Sun Oct  9 14:14:40 2022
From: @|ex@ndre@court|o| @end|ng |rom gm@||@com (Alexandre Courtiol)
Date: Sun, 9 Oct 2022 14:14:40 +0200
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
Message-ID: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>

Hi R pkg developers,

We are facing a datetime handling issue which manifests itself in a
package we are working on.

In context, we noticed that reading datetime info from an excel file
resulted in different data depending on the computer we used.

We are aware that timezone and regional settings are general sources
of troubles, but the code we are using was trying to circumvent this.
We went only as far as figuring out that the issue happens when
converting a POSIXlt into a POSIXct.

Please find below, a minimal reproducible example where `foo` is
converted to `bar` on two different computers.
`foo` is a POSIXlt with a defined time zone and upon conversion to a
POSIXct, despite using a set time zone, we end up with `bar` being
different on Linux and on a Windows machine.

We noticed that the difference emerges from the system call
`.Internal(as.POSIXct())` within `as.POSIXct.POSIXlt()`.
We also noticed that the internal function in R actually calls
getenv("TZ") within C, which is probably what explains where the
difference comes from.

Such a behaviour is probably expected and not a bug, but what would be
the strategy to convert a POSIXlt into a POSIXct that would not be
machine dependent?

We finally noticed that depending on the datetime used as a starting
point and on the time zone used when calling `as.POSIXct()`, we
sometimes have a difference between computers and sometimes not...
which adds to our puzzlement.

Many thanks.
Alex & Liam


``` r
## On Linux
foo <- structure(list(sec = 0, min = 0L, hour = 0L, mday = 1L, mon =
9L, year = 121L, wday = 5L, yday = 273L, isdst = 0L),
                 class = c("POSIXlt", "POSIXt"), tzone = "UTC")

bar <- as.POSIXct(foo, tz = "Europe/Berlin")

bar
#> [1] "2021-10-01 01:00:00 CEST"

dput(bar)
#> structure(1633042800, class = c("POSIXct", "POSIXt"), tzone =
"Europe/Berlin")
```

``` r
## On Windows
foo <- structure(list(sec = 0, min = 0L, hour = 0L, mday = 1L, mon =
9L, year = 121L, wday = 5L, yday = 273L, isdst = 0L),
                 class = c("POSIXlt", "POSIXt"), tzone = "UTC")

bar <- as.POSIXct(foo, tz = "Europe/Berlin")

bar
#> [1] "2021-10-01 CEST"

dput(bar)
structure(1633046400, class = c("POSIXct", "POSIXt"), tzone = "Europe/Berlin")
```

-- 
Alexandre Courtiol, www.datazoogang.de


From @|mon@urb@nek @end|ng |rom R-project@org  Mon Oct 10 03:57:06 2022
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Mon, 10 Oct 2022 14:57:06 +1300
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
Message-ID: <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>

Alexandre,

it's better to parse the timestamp in correct timezone:

> foo = as.POSIXlt("2021-10-01", "UTC")
> as.POSIXct(as.character(foo), "Europe/Berlin")
[1] "2021-10-01 CEST"

The issue stems from the fact that you are pretending like your timestamp is UTC (which it is not) while you want to interpret the same values in a different time zone. The DST flags varies depending on the day (due to DST being 0 or 1 depending on the date) and POSIXlt does not have that information since you only attached the time zone without updating it:

> str(unclass(as.POSIXlt(foo, "Europe/Berlin")))
List of 9
 $ sec  : num 0
 $ min  : int 0
 $ hour : int 0
 $ mday : int 1
 $ mon  : int 9
 $ year : int 121
 $ wday : int 5
 $ yday : int 273
 $ isdst: int 0
 - attr(*, "tzone")= chr "Europe/Berlin"

note that isdst is 0 from the UTC entry (which doesn't have DST) even though that date is actually DST in CEST. Compare that to the correctly parsed POSIXlt:

> str(unclass(as.POSIXlt(as.character(foo), "Europe/Berlin")))
List of 11
 $ sec   : num 0
 $ min   : int 0
 $ hour  : int 0
 $ mday  : int 1
 $ mon   : int 9
 $ year  : int 121
 $ wday  : int 5
 $ yday  : int 273
 $ isdst : int 1
 $ zone  : chr "CEST"
 $ gmtoff: int NA
 - attr(*, "tzone")= chr "Europe/Berlin"

where isdst is 1 since it is indeed the DST. The OS difference seems to be that Linux respects the isdst information from POSIXlt while Windows and macOS ignores it. This behavior is documented: 

     At all other times ?isdst? can be deduced from the
     first six values, but the behaviour if it is set incorrectly is
     platform-dependent.

You can re-set isdst to -1 to make sure R will try to determine it:

> foo$isdst = -1L
> as.POSIXct(foo, "Europe/Berlin")
[1] "2021-10-01 CEST"

So, generally, you cannot simply change the time zone in POSIXlt - don't pretend the time is in UTC if it's not, you have to re-parse or re-compute the timestamps for it to be reliable or else the DST flag will be wrong.

Cheers,
Simon


> On 10/10/2022, at 1:14 AM, Alexandre Courtiol <alexandre.courtiol at gmail.com> wrote:
> 
> Hi R pkg developers,
> 
> We are facing a datetime handling issue which manifests itself in a
> package we are working on.
> 
> In context, we noticed that reading datetime info from an excel file
> resulted in different data depending on the computer we used.
> 
> We are aware that timezone and regional settings are general sources
> of troubles, but the code we are using was trying to circumvent this.
> We went only as far as figuring out that the issue happens when
> converting a POSIXlt into a POSIXct.
> 
> Please find below, a minimal reproducible example where `foo` is
> converted to `bar` on two different computers.
> `foo` is a POSIXlt with a defined time zone and upon conversion to a
> POSIXct, despite using a set time zone, we end up with `bar` being
> different on Linux and on a Windows machine.
> 
> We noticed that the difference emerges from the system call
> `.Internal(as.POSIXct())` within `as.POSIXct.POSIXlt()`.
> We also noticed that the internal function in R actually calls
> getenv("TZ") within C, which is probably what explains where the
> difference comes from.
> 
> Such a behaviour is probably expected and not a bug, but what would be
> the strategy to convert a POSIXlt into a POSIXct that would not be
> machine dependent?
> 
> We finally noticed that depending on the datetime used as a starting
> point and on the time zone used when calling `as.POSIXct()`, we
> sometimes have a difference between computers and sometimes not...
> which adds to our puzzlement.
> 
> Many thanks.
> Alex & Liam
> 
> 
> ``` r
> ## On Linux
> foo <- structure(list(sec = 0, min = 0L, hour = 0L, mday = 1L, mon =
> 9L, year = 121L, wday = 5L, yday = 273L, isdst = 0L),
>                 class = c("POSIXlt", "POSIXt"), tzone = "UTC")
> 
> bar <- as.POSIXct(foo, tz = "Europe/Berlin")
> 
> bar
> #> [1] "2021-10-01 01:00:00 CEST"
> 
> dput(bar)
> #> structure(1633042800, class = c("POSIXct", "POSIXt"), tzone =
> "Europe/Berlin")
> ```
> 
> ``` r
> ## On Windows
> foo <- structure(list(sec = 0, min = 0L, hour = 0L, mday = 1L, mon =
> 9L, year = 121L, wday = 5L, yday = 273L, isdst = 0L),
>                 class = c("POSIXlt", "POSIXt"), tzone = "UTC")
> 
> bar <- as.POSIXct(foo, tz = "Europe/Berlin")
> 
> bar
> #> [1] "2021-10-01 CEST"
> 
> dput(bar)
> structure(1633046400, class = c("POSIXct", "POSIXt"), tzone = "Europe/Berlin")
> ```
> 
> -- 
> Alexandre Courtiol, www.datazoogang.de
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Oct 10 04:31:03 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 09 Oct 2022 19:31:03 -0700
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
 <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
Message-ID: <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>

... which is why tidyverse functions and Python datetime handling irk me so much.

Is tidyverse time handling intrinsically broken? They have a standard practice of reading time as UTC and then using force_tz to fix the "mistake". Same as Python.

On October 9, 2022 6:57:06 PM PDT, Simon Urbanek <simon.urbanek at R-project.org> wrote:
>Alexandre,
>
>it's better to parse the timestamp in correct timezone:
>
>> foo = as.POSIXlt("2021-10-01", "UTC")
>> as.POSIXct(as.character(foo), "Europe/Berlin")
>[1] "2021-10-01 CEST"
>
>The issue stems from the fact that you are pretending like your timestamp is UTC (which it is not) while you want to interpret the same values in a different time zone. The DST flags varies depending on the day (due to DST being 0 or 1 depending on the date) and POSIXlt does not have that information since you only attached the time zone without updating it:
>
>> str(unclass(as.POSIXlt(foo, "Europe/Berlin")))
>List of 9
> $ sec  : num 0
> $ min  : int 0
> $ hour : int 0
> $ mday : int 1
> $ mon  : int 9
> $ year : int 121
> $ wday : int 5
> $ yday : int 273
> $ isdst: int 0
> - attr(*, "tzone")= chr "Europe/Berlin"
>
>note that isdst is 0 from the UTC entry (which doesn't have DST) even though that date is actually DST in CEST. Compare that to the correctly parsed POSIXlt:
>
>> str(unclass(as.POSIXlt(as.character(foo), "Europe/Berlin")))
>List of 11
> $ sec   : num 0
> $ min   : int 0
> $ hour  : int 0
> $ mday  : int 1
> $ mon   : int 9
> $ year  : int 121
> $ wday  : int 5
> $ yday  : int 273
> $ isdst : int 1
> $ zone  : chr "CEST"
> $ gmtoff: int NA
> - attr(*, "tzone")= chr "Europe/Berlin"
>
>where isdst is 1 since it is indeed the DST. The OS difference seems to be that Linux respects the isdst information from POSIXlt while Windows and macOS ignores it. This behavior is documented: 
>
>     At all other times ?isdst? can be deduced from the
>     first six values, but the behaviour if it is set incorrectly is
>     platform-dependent.
>
>You can re-set isdst to -1 to make sure R will try to determine it:
>
>> foo$isdst = -1L
>> as.POSIXct(foo, "Europe/Berlin")
>[1] "2021-10-01 CEST"
>
>So, generally, you cannot simply change the time zone in POSIXlt - don't pretend the time is in UTC if it's not, you have to re-parse or re-compute the timestamps for it to be reliable or else the DST flag will be wrong.
>
>Cheers,
>Simon
>
>
>> On 10/10/2022, at 1:14 AM, Alexandre Courtiol <alexandre.courtiol at gmail.com> wrote:
>> 
>> Hi R pkg developers,
>> 
>> We are facing a datetime handling issue which manifests itself in a
>> package we are working on.
>> 
>> In context, we noticed that reading datetime info from an excel file
>> resulted in different data depending on the computer we used.
>> 
>> We are aware that timezone and regional settings are general sources
>> of troubles, but the code we are using was trying to circumvent this.
>> We went only as far as figuring out that the issue happens when
>> converting a POSIXlt into a POSIXct.
>> 
>> Please find below, a minimal reproducible example where `foo` is
>> converted to `bar` on two different computers.
>> `foo` is a POSIXlt with a defined time zone and upon conversion to a
>> POSIXct, despite using a set time zone, we end up with `bar` being
>> different on Linux and on a Windows machine.
>> 
>> We noticed that the difference emerges from the system call
>> `.Internal(as.POSIXct())` within `as.POSIXct.POSIXlt()`.
>> We also noticed that the internal function in R actually calls
>> getenv("TZ") within C, which is probably what explains where the
>> difference comes from.
>> 
>> Such a behaviour is probably expected and not a bug, but what would be
>> the strategy to convert a POSIXlt into a POSIXct that would not be
>> machine dependent?
>> 
>> We finally noticed that depending on the datetime used as a starting
>> point and on the time zone used when calling `as.POSIXct()`, we
>> sometimes have a difference between computers and sometimes not...
>> which adds to our puzzlement.
>> 
>> Many thanks.
>> Alex & Liam
>> 
>> 
>> ``` r
>> ## On Linux
>> foo <- structure(list(sec = 0, min = 0L, hour = 0L, mday = 1L, mon =
>> 9L, year = 121L, wday = 5L, yday = 273L, isdst = 0L),
>>                 class = c("POSIXlt", "POSIXt"), tzone = "UTC")
>> 
>> bar <- as.POSIXct(foo, tz = "Europe/Berlin")
>> 
>> bar
>> #> [1] "2021-10-01 01:00:00 CEST"
>> 
>> dput(bar)
>> #> structure(1633042800, class = c("POSIXct", "POSIXt"), tzone =
>> "Europe/Berlin")
>> ```
>> 
>> ``` r
>> ## On Windows
>> foo <- structure(list(sec = 0, min = 0L, hour = 0L, mday = 1L, mon =
>> 9L, year = 121L, wday = 5L, yday = 273L, isdst = 0L),
>>                 class = c("POSIXlt", "POSIXt"), tzone = "UTC")
>> 
>> bar <- as.POSIXct(foo, tz = "Europe/Berlin")
>> 
>> bar
>> #> [1] "2021-10-01 CEST"
>> 
>> dput(bar)
>> structure(1633046400, class = c("POSIXct", "POSIXt"), tzone = "Europe/Berlin")
>> ```
>> 
>> -- 
>> Alexandre Courtiol, www.datazoogang.de
>> 
>> ______________________________________________
>> R-package-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>> 
>
>______________________________________________
>R-package-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-package-devel

-- 
Sent from my phone. Please excuse my brevity.


From d@tr7320 @end|ng |rom un|@@ydney@edu@@u  Mon Oct 10 10:00:04 2022
From: d@tr7320 @end|ng |rom un|@@ydney@edu@@u (Dario Strbenac)
Date: Mon, 10 Oct 2022 08:00:04 +0000
Subject: [R-pkg-devel] Identify Original Column Names of Model Matrix
Message-ID: <SY2PR01MB30033EFCF280CCC2EB45B06DCD209@SY2PR01MB3003.ausprd01.prod.outlook.com>

Good day,

I am developing a wrapper around xgboost which does not (yet - I see that it is on the developer's version 2.0 task list) support factor variable type. It requires input data to be in one-hot encoding, which is created by Matrix::sparse.model.matrix. For further analysis, such as variable importance, is there a way to identify which original feature each column of a sparse.model.matrix result was derived from? Using str(oneHotMatrix), I don't see any class slots nor tacked-on attributes which would confidently allow the identification of original column names of the expanded input data. Is there an alternative way to robustly identify the original variable names?

--------------------------------------
Dario Strbenac
University of Sydney
Camperdown NSW 2050
Australia

From h@w|ckh@m @end|ng |rom gm@||@com  Mon Oct 10 18:40:42 2022
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Mon, 10 Oct 2022 11:40:42 -0500
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
 <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
 <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>
Message-ID: <CABdHhvFv32jRvm9WHX4dckOjWs1LK=tV=134K-0cOAgzvvDi=A@mail.gmail.com>

On Sun, Oct 9, 2022 at 9:31 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> ... which is why tidyverse functions and Python datetime handling irk me so much.
>
> Is tidyverse time handling intrinsically broken? They have a standard practice of reading time as UTC and then using force_tz to fix the "mistake". Same as Python.

Can you point to any docs that lead you to this conclusion so we can
get them fixed? I strongly encourage people to parse date-times in the
correct time zone; this is why lubridate::ymd_hms() and friends have a
tz argument.

Hadley

-- 
http://hadley.nz


From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Mon Oct 10 22:12:21 2022
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Mon, 10 Oct 2022 15:12:21 -0500
Subject: [R-pkg-devel] Rd cross-references to Suggested package
Message-ID: <CAPPM_gT_Fh61FzGmrsQZt7dNWiZs6J6pxjFwiGGUNbQ2hQbhNw@mail.gmail.com>

Hi all,

I'd like to link to a help page of a package in my package's Suggests.
WRE, section 2.5 says,

"Historically (before R version 4.1.0), links of the form
\link[pkg]{foo} and \link[pkg:bar]{foo} used to be interpreted as
links to files foo.html and bar.html in package pkg, respectively. For
this reason, the HTML help system looks for file foo.html in package
pkg if it does not find topic foo, and then searches for the topic in
other installed packages. To test that links work both with both old
and new systems, the pre-4.1.0 behaviour can be restored by setting
the environment variable _R_HELP_LINKS_TO_TOPICS_=false.

"Packages referred to by these ?other forms? should be declared in the
DESCRIPTION file, in the ?Depends?, ?Im
ports?, ?Suggests? or ?Enhances? fields."

This seems to imply that it's possible... though I don't understand
when I need to set _R_HELP_LINKS_TO_TOPICS_=false in order to test
that the link is done correctly. I'm using \link[pkg]{foo} in R 4.2.1.

I ran R CMD build/INSTALL/check with and without that env var set to
false. Both times the suggested package was not installed on my
library path, so I had to set _R_CHECK_FORCE_SUGGESTS_=false for R CMD
check --as-cran.

I didn't notice a difference in output from R CMD check. Both runs had:

    * checking Rd cross-references ... NOTE
    Package unavailable to check Rd xrefs: ?timeSeries?

I'd appreciate any thoughts and/or pointers to other documentation.

Best,
Josh


-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From @|mon@urb@nek @end|ng |rom R-project@org  Mon Oct 10 22:13:16 2022
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Tue, 11 Oct 2022 09:13:16 +1300
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <C86BDDF6-44EE-4B9B-9515-F19F954B5337@liamdbailey.com>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
 <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
 <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>
 <CABdHhvFv32jRvm9WHX4dckOjWs1LK=tV=134K-0cOAgzvvDi=A@mail.gmail.com>
 <C86BDDF6-44EE-4B9B-9515-F19F954B5337@liamdbailey.com>
Message-ID: <03EBA665-067E-45F4-A97B-4E94E98D65A8@R-project.org>

Liam,

I think I have failed to convey my main point in the last e-mail - which was that you want to parse the date/time in the timezone that you care about so in your example that would be

> foo <- as.Date(33874, origin = "1899-12-30")
> foo
[1] "1992-09-27"
> as.POSIXlt(as.character(foo), "Europe/Berlin")
[1] "1992-09-27 CEST"

I was explicitly saying that you do NOT want to simply change the time zone on POSIXlt objects as that won't work for reasons I explained - see my last e-mail.

Cheers,
Simon


> On 11/10/2022, at 6:31 AM, Liam Bailey <liam.bailey at liamdbailey.com> wrote:
> 
> Hi all,
> 
> Thanks Simon for the detailed response, that helps us understand a lot better what?s going on! However, with your response in mind, we still encounter some behaviour that we did not expect.
> 
> I?ve included another minimum reproducible example below to expand on the situation. In this example, `foo` is a Date object that we generate from a numeric input. Following your advice, `bar` is then a POSIXlt object where we now explicitly define timezone using argument tz. However, even though we are explicit about the timezone the POSIXlt that is generated is always in UTC. This then leads to the issues outlined by Alexandre above, which we now understand are caused by DST.
> 
> ``` r
> #Generate date from numeric
>     #Not possible to specify tz at this point
>     foo <- as.Date(33874, origin = "1899-12-30")
>     dput(foo)
> #> structure(8305, class = "Date")
>     
>     #Convert to POSIXlt specifying UTC timezone
>     bar <- as.POSIXlt(foo, tz = "UTC")
>     dput(bar)
> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L, 
> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class = c("POSIXlt", 
> #> "POSIXt"), tzone = "UTC")
>     
>     #Convert to POSIXlt specifying Europe/Berlin.
>     #Time zone is still UTC
>     bar <- as.POSIXlt(foo, tz = "Europe/Berlin")
>     dput(bar)
> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L, 
> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class = c("POSIXlt", 
> #> "POSIXt"), tzone = "UTC")
> ```
> 
> 
> We noticed that this occurs because the tz argument is not passed to `.Internal(Date2POSIXlt())` inside `as.POSIXlt.Date()`.
> 
> Reading through the documentation for `as.POSIX*` we can see that this behaviour is described:
> 
> 	> ?Dates without times are treated as being at midnight UTC.?
> 
> In this case, if we want to convert a Date object to POSIX* and specify a (non-UTC) timezone would the best strategy be to first coerce our Date object to character? Alternatively, `lubridate::as_datetime()` does seem to recognise the tz argument and convert a Date object to POSIX* with non-UTC time zone (see second example below). But it would be nice to know if there are subtle differences between these two approaches that we should be aware of.
> 
> ``` r
> foo <- as.Date(33874, origin = "1899-12-30")
> dput(foo)
> #> structure(8305, class = "Date")
> 
> #Convert to POSIXct specifying UTC timezone
> bar <- lubridate::as_datetime(foo, tz = "UTC")
> dput(as.POSIXlt(bar))
> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L, 
> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class = c("POSIXlt", 
> #> "POSIXt"), tzone = "UTC")
> 
> #Convert to POSIXct specifying Europe/Berlin
> bar <- lubridate::as_datetime(foo, tz = "Europe/Berlin")
> dput(as.POSIXlt(bar))
> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L, 
> #>     year = 92L, wday = 0L, yday = 270L, isdst = 1L, zone = "CEST", 
> #>     gmtoff = 7200L), class = c("POSIXlt", "POSIXt"), tzone = c("Europe/Berlin", 
> #> "CET", "CEST"))
> ```
> 
> Thanks again for all your help.
> Alex & Liam
> 
>> On 10 Oct 2022, at 6:40 pm, Hadley Wickham <h.wickham at gmail.com> wrote:
>> 
>> On Sun, Oct 9, 2022 at 9:31 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> ... which is why tidyverse functions and Python datetime handling irk me so much.
>>> 
>>> Is tidyverse time handling intrinsically broken? They have a standard practice of reading time as UTC and then using force_tz to fix the "mistake". Same as Python.
>> 
>> Can you point to any docs that lead you to this conclusion so we can
>> get them fixed? I strongly encourage people to parse date-times in the
>> correct time zone; this is why lubridate::ymd_hms() and friends have a
>> tz argument.
>> 
>> Hadley
>> 
>> -- 
>> http://hadley.nz
> 


From @|ex@ndre@court|o| @end|ng |rom gm@||@com  Mon Oct 10 22:50:26 2022
From: @|ex@ndre@court|o| @end|ng |rom gm@||@com (Alexandre Courtiol)
Date: Mon, 10 Oct 2022 22:50:26 +0200
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <03EBA665-067E-45F4-A97B-4E94E98D65A8@R-project.org>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
 <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
 <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>
 <CABdHhvFv32jRvm9WHX4dckOjWs1LK=tV=134K-0cOAgzvvDi=A@mail.gmail.com>
 <C86BDDF6-44EE-4B9B-9515-F19F954B5337@liamdbailey.com>
 <03EBA665-067E-45F4-A97B-4E94E98D65A8@R-project.org>
Message-ID: <CAERMt4doKk0OFujPOzi7vNz6NrzHV8c56=5=CKMhfWBtyFbY3Q@mail.gmail.com>

Hi Simon,

Thanks for the clarification.

From a naive developer point of view, we were initially baffled that the
generic as.POSIXlt() does very different things on a character and on a
Date input:

as.POSIXlt(as.character(foo), "Europe/Berlin")
[1] "1992-09-27 CEST"

as.POSIXlt(foo, "Europe/Berlin")
[1] "1992-09-27 UTC"

Based on what you said, it does make sense: it is only when creating the
date/time that we want to include the time zone and that only happens when
we don't already work on a previously created date.
That is your subtle but spot-on distinction between "parsing" and
"changing" the time zone.

Yet, we do find it dangerous that as.POSIXlt.Date() accepts a time zone but
does nothing of it, especially when the help file starts with:

Usage
as.POSIXlt(x, tz = "", ...)

The behaviour is documented, as Liam reported it, but still, we will almost
certainly not be the last one tripping on this (without even adding the
additional issue of as.POSIXct() behaving differently across OS).

Thanks again,

Alex & Liam




On Mon, 10 Oct 2022 at 22:13, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> Liam,
>
> I think I have failed to convey my main point in the last e-mail - which
> was that you want to parse the date/time in the timezone that you care
> about so in your example that would be
>
> > foo <- as.Date(33874, origin = "1899-12-30")
> > foo
> [1] "1992-09-27"
> > as.POSIXlt(as.character(foo), "Europe/Berlin")
> [1] "1992-09-27 CEST"
>
> I was explicitly saying that you do NOT want to simply change the time
> zone on POSIXlt objects as that won't work for reasons I explained - see my
> last e-mail.
>
> Cheers,
> Simon
>
>
> > On 11/10/2022, at 6:31 AM, Liam Bailey <liam.bailey at liamdbailey.com>
> wrote:
> >
> > Hi all,
> >
> > Thanks Simon for the detailed response, that helps us understand a lot
> better what?s going on! However, with your response in mind, we still
> encounter some behaviour that we did not expect.
> >
> > I?ve included another minimum reproducible example below to expand on
> the situation. In this example, `foo` is a Date object that we generate
> from a numeric input. Following your advice, `bar` is then a POSIXlt object
> where we now explicitly define timezone using argument tz. However, even
> though we are explicit about the timezone the POSIXlt that is generated is
> always in UTC. This then leads to the issues outlined by Alexandre above,
> which we now understand are caused by DST.
> >
> > ``` r
> > #Generate date from numeric
> >     #Not possible to specify tz at this point
> >     foo <- as.Date(33874, origin = "1899-12-30")
> >     dput(foo)
> > #> structure(8305, class = "Date")
> >
> >     #Convert to POSIXlt specifying UTC timezone
> >     bar <- as.POSIXlt(foo, tz = "UTC")
> >     dput(bar)
> > #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
> > #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
> c("POSIXlt",
> > #> "POSIXt"), tzone = "UTC")
> >
> >     #Convert to POSIXlt specifying Europe/Berlin.
> >     #Time zone is still UTC
> >     bar <- as.POSIXlt(foo, tz = "Europe/Berlin")
> >     dput(bar)
> > #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
> > #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
> c("POSIXlt",
> > #> "POSIXt"), tzone = "UTC")
> > ```
> >
> >
> > We noticed that this occurs because the tz argument is not passed to
> `.Internal(Date2POSIXlt())` inside `as.POSIXlt.Date()`.
> >
> > Reading through the documentation for `as.POSIX*` we can see that this
> behaviour is described:
> >
> >       > ?Dates without times are treated as being at midnight UTC.?
> >
> > In this case, if we want to convert a Date object to POSIX* and specify
> a (non-UTC) timezone would the best strategy be to first coerce our Date
> object to character? Alternatively, `lubridate::as_datetime()` does seem to
> recognise the tz argument and convert a Date object to POSIX* with non-UTC
> time zone (see second example below). But it would be nice to know if there
> are subtle differences between these two approaches that we should be aware
> of.
> >
> > ``` r
> > foo <- as.Date(33874, origin = "1899-12-30")
> > dput(foo)
> > #> structure(8305, class = "Date")
> >
> > #Convert to POSIXct specifying UTC timezone
> > bar <- lubridate::as_datetime(foo, tz = "UTC")
> > dput(as.POSIXlt(bar))
> > #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
> > #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
> c("POSIXlt",
> > #> "POSIXt"), tzone = "UTC")
> >
> > #Convert to POSIXct specifying Europe/Berlin
> > bar <- lubridate::as_datetime(foo, tz = "Europe/Berlin")
> > dput(as.POSIXlt(bar))
> > #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
> > #>     year = 92L, wday = 0L, yday = 270L, isdst = 1L, zone = "CEST",
> > #>     gmtoff = 7200L), class = c("POSIXlt", "POSIXt"), tzone =
> c("Europe/Berlin",
> > #> "CET", "CEST"))
> > ```
> >
> > Thanks again for all your help.
> > Alex & Liam
> >
> >> On 10 Oct 2022, at 6:40 pm, Hadley Wickham <h.wickham at gmail.com> wrote:
> >>
> >> On Sun, Oct 9, 2022 at 9:31 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >>>
> >>> ... which is why tidyverse functions and Python datetime handling irk
> me so much.
> >>>
> >>> Is tidyverse time handling intrinsically broken? They have a standard
> practice of reading time as UTC and then using force_tz to fix the
> "mistake". Same as Python.
> >>
> >> Can you point to any docs that lead you to this conclusion so we can
> >> get them fixed? I strongly encourage people to parse date-times in the
> >> correct time zone; this is why lubridate::ymd_hms() and friends have a
> >> tz argument.
> >>
> >> Hadley
> >>
> >> --
> >> http://hadley.nz
> >
>
>

-- 
Alexandre Courtiol, www.datazoogang.de

	[[alternative HTML version deleted]]


From d|ego@hern@ngomezherrero @end|ng |rom gm@||@com  Mon Oct 10 17:25:49 2022
From: d|ego@hern@ngomezherrero @end|ng |rom gm@||@com (=?UTF-8?Q?Diego_Hernang=C3=B3mez_Herrero?=)
Date: Mon, 10 Oct 2022 17:25:49 +0200
Subject: [R-pkg-devel] Best way forward on a CRAN archived package
Message-ID: <CAA-ibaxp8a5uttw3hci2ZUXit-CjJZf4uaYaqR4zRuD--tAMrw@mail.gmail.com>

Hi:

I have some doubts on how to proceed in this case. I am the developer of
tidyterra, and I received an email from CRAN on 23Sep2022 about an issue on
the package, setting a deadline on 07Oct2022 to correct it.

I sent a patch that was accepted on CRAN on 29Sep2022, that fixed the issue
(or at least I am pretty sure I solved it). I received no further feedback
by CRAN, so I assumed the package was safe. However it was finally archived
on 07Oct2022.

I have already sent an email to CRAN in order to check if they think the
issues still persist (or maybe they missed the patch submission?), but I am
in a rush since there are other packages that depend on tidyterra and they
may be in risk of being archived on CRAN as well.

So my question is: What is the best way forward at this point? Should I
wait to get some feedback from CRAN or is it best to resubmit the package
(I already have a new patch prepared)? I acknowledge that  "The time of the
volunteers is CRAN?s most precious resource" so my goal is to reduce their
burden as much as possible.

Kind regards

-- 



Have a nice day!

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 10 22:59:35 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 10 Oct 2022 16:59:35 -0400
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <CAERMt4doKk0OFujPOzi7vNz6NrzHV8c56=5=CKMhfWBtyFbY3Q@mail.gmail.com>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
 <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
 <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>
 <CABdHhvFv32jRvm9WHX4dckOjWs1LK=tV=134K-0cOAgzvvDi=A@mail.gmail.com>
 <C86BDDF6-44EE-4B9B-9515-F19F954B5337@liamdbailey.com>
 <03EBA665-067E-45F4-A97B-4E94E98D65A8@R-project.org>
 <CAERMt4doKk0OFujPOzi7vNz6NrzHV8c56=5=CKMhfWBtyFbY3Q@mail.gmail.com>
Message-ID: <2e92f0f1-ddfd-1c74-4805-ac65821ccd81@gmail.com>

   Right now as.POSIXlt.Date() is just

function (x, ...)
.Internal(Date2POSIXlt(x))

How expensive would it be to throw a warning when '...' is provided by 
the user/discarded ??

Alternately, perhaps the documentation could be amended, although I'm 
not quite sure what to suggest. (The sentence Liam refers to, "Dates 
without times are treated as being at midnight UTC." is correct but 
terse ...)


On 2022-10-10 4:50 p.m., Alexandre Courtiol wrote:
> Hi Simon,
> 
> Thanks for the clarification.
> 
>  From a naive developer point of view, we were initially baffled that the
> generic as.POSIXlt() does very different things on a character and on a
> Date input:
> 
> as.POSIXlt(as.character(foo), "Europe/Berlin")
> [1] "1992-09-27 CEST"
> 
> as.POSIXlt(foo, "Europe/Berlin")
> [1] "1992-09-27 UTC"
> 
> Based on what you said, it does make sense: it is only when creating the
> date/time that we want to include the time zone and that only happens when
> we don't already work on a previously created date.
> That is your subtle but spot-on distinction between "parsing" and
> "changing" the time zone.
> 
> Yet, we do find it dangerous that as.POSIXlt.Date() accepts a time zone but
> does nothing of it, especially when the help file starts with:
> 
> Usage
> as.POSIXlt(x, tz = "", ...)
> 
> The behaviour is documented, as Liam reported it, but still, we will almost
> certainly not be the last one tripping on this (without even adding the
> additional issue of as.POSIXct() behaving differently across OS).
> 
> Thanks again,
> 
> Alex & Liam
> 
> 
> 
> 
> On Mon, 10 Oct 2022 at 22:13, Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
> 
>> Liam,
>>
>> I think I have failed to convey my main point in the last e-mail - which
>> was that you want to parse the date/time in the timezone that you care
>> about so in your example that would be
>>
>>> foo <- as.Date(33874, origin = "1899-12-30")
>>> foo
>> [1] "1992-09-27"
>>> as.POSIXlt(as.character(foo), "Europe/Berlin")
>> [1] "1992-09-27 CEST"
>>
>> I was explicitly saying that you do NOT want to simply change the time
>> zone on POSIXlt objects as that won't work for reasons I explained - see my
>> last e-mail.
>>
>> Cheers,
>> Simon
>>
>>
>>> On 11/10/2022, at 6:31 AM, Liam Bailey <liam.bailey at liamdbailey.com>
>> wrote:
>>>
>>> Hi all,
>>>
>>> Thanks Simon for the detailed response, that helps us understand a lot
>> better what?s going on! However, with your response in mind, we still
>> encounter some behaviour that we did not expect.
>>>
>>> I?ve included another minimum reproducible example below to expand on
>> the situation. In this example, `foo` is a Date object that we generate
>> from a numeric input. Following your advice, `bar` is then a POSIXlt object
>> where we now explicitly define timezone using argument tz. However, even
>> though we are explicit about the timezone the POSIXlt that is generated is
>> always in UTC. This then leads to the issues outlined by Alexandre above,
>> which we now understand are caused by DST.
>>>
>>> ``` r
>>> #Generate date from numeric
>>>      #Not possible to specify tz at this point
>>>      foo <- as.Date(33874, origin = "1899-12-30")
>>>      dput(foo)
>>> #> structure(8305, class = "Date")
>>>
>>>      #Convert to POSIXlt specifying UTC timezone
>>>      bar <- as.POSIXlt(foo, tz = "UTC")
>>>      dput(bar)
>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
>> c("POSIXlt",
>>> #> "POSIXt"), tzone = "UTC")
>>>
>>>      #Convert to POSIXlt specifying Europe/Berlin.
>>>      #Time zone is still UTC
>>>      bar <- as.POSIXlt(foo, tz = "Europe/Berlin")
>>>      dput(bar)
>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
>> c("POSIXlt",
>>> #> "POSIXt"), tzone = "UTC")
>>> ```
>>>
>>>
>>> We noticed that this occurs because the tz argument is not passed to
>> `.Internal(Date2POSIXlt())` inside `as.POSIXlt.Date()`.
>>>
>>> Reading through the documentation for `as.POSIX*` we can see that this
>> behaviour is described:
>>>
>>>        > ?Dates without times are treated as being at midnight UTC.?
>>>
>>> In this case, if we want to convert a Date object to POSIX* and specify
>> a (non-UTC) timezone would the best strategy be to first coerce our Date
>> object to character? Alternatively, `lubridate::as_datetime()` does seem to
>> recognise the tz argument and convert a Date object to POSIX* with non-UTC
>> time zone (see second example below). But it would be nice to know if there
>> are subtle differences between these two approaches that we should be aware
>> of.
>>>
>>> ``` r
>>> foo <- as.Date(33874, origin = "1899-12-30")
>>> dput(foo)
>>> #> structure(8305, class = "Date")
>>>
>>> #Convert to POSIXct specifying UTC timezone
>>> bar <- lubridate::as_datetime(foo, tz = "UTC")
>>> dput(as.POSIXlt(bar))
>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
>> c("POSIXlt",
>>> #> "POSIXt"), tzone = "UTC")
>>>
>>> #Convert to POSIXct specifying Europe/Berlin
>>> bar <- lubridate::as_datetime(foo, tz = "Europe/Berlin")
>>> dput(as.POSIXlt(bar))
>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 1L, zone = "CEST",
>>> #>     gmtoff = 7200L), class = c("POSIXlt", "POSIXt"), tzone =
>> c("Europe/Berlin",
>>> #> "CET", "CEST"))
>>> ```
>>>
>>> Thanks again for all your help.
>>> Alex & Liam
>>>
>>>> On 10 Oct 2022, at 6:40 pm, Hadley Wickham <h.wickham at gmail.com> wrote:
>>>>
>>>> On Sun, Oct 9, 2022 at 9:31 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>>>>
>>>>> ... which is why tidyverse functions and Python datetime handling irk
>> me so much.
>>>>>
>>>>> Is tidyverse time handling intrinsically broken? They have a standard
>> practice of reading time as UTC and then using force_tz to fix the
>> "mistake". Same as Python.
>>>>
>>>> Can you point to any docs that lead you to this conclusion so we can
>>>> get them fixed? I strongly encourage people to parse date-times in the
>>>> correct time zone; this is why lubridate::ymd_hms() and friends have a
>>>> tz argument.
>>>>
>>>> Hadley
>>>>
>>>> --
>>>> http://hadley.nz
>>>
>>
>>
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Oct 10 23:19:36 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 10 Oct 2022 14:19:36 -0700
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <CABdHhvFv32jRvm9WHX4dckOjWs1LK=tV=134K-0cOAgzvvDi=A@mail.gmail.com>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
 <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
 <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>
 <CABdHhvFv32jRvm9WHX4dckOjWs1LK=tV=134K-0cOAgzvvDi=A@mail.gmail.com>
Message-ID: <AF4FFF49-E534-4AFD-A7CE-C1FF9E343733@dcn.davis.ca.us>

I have no idea how to get readxl::read_excel to import a timestamp column in a timezone. It is true that Excel has no concept of timezones, but the data one finds there usually came from a text file at some point. Importing as character is a feasible strategy, but trying to convince an intermediate user to go to that much trouble is a headache when the issue is ignored in the help file.

It is evidently possible to specify a locale input to readr::read_csv, but the default behaviour guesses timestamp columns and assumes "UTC", and a file may contain data from different timezones (UTC and local civil are a common combination). Again, character import and manual conversion are needed.

On October 10, 2022 9:40:42 AM PDT, Hadley Wickham <h.wickham at gmail.com> wrote:
>On Sun, Oct 9, 2022 at 9:31 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> ... which is why tidyverse functions and Python datetime handling irk me so much.
>>
>> Is tidyverse time handling intrinsically broken? They have a standard practice of reading time as UTC and then using force_tz to fix the "mistake". Same as Python.
>
>Can you point to any docs that lead you to this conclusion so we can
>get them fixed? I strongly encourage people to parse date-times in the
>correct time zone; this is why lubridate::ymd_hms() and friends have a
>tz argument.
>
>Hadley
>

-- 
Sent from my phone. Please excuse my brevity.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 11 08:58:01 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 11 Oct 2022 08:58:01 +0200
Subject: [R-pkg-devel] Issue handling datetimes: possible differences
 between computers
In-Reply-To: <2e92f0f1-ddfd-1c74-4805-ac65821ccd81@gmail.com>
References: <CAERMt4eYyTKadiTk6ZVgM5UmVXQ83PbBJQzfBOEW7=KZqsBC+w@mail.gmail.com>
 <24D0D7FC-F6DF-4AB2-B5A3-7E14D631804C@R-project.org>
 <16B5505C-DAE0-4735-AED3-92B86E7A0DD8@dcn.davis.ca.us>
 <CABdHhvFv32jRvm9WHX4dckOjWs1LK=tV=134K-0cOAgzvvDi=A@mail.gmail.com>
 <C86BDDF6-44EE-4B9B-9515-F19F954B5337@liamdbailey.com>
 <03EBA665-067E-45F4-A97B-4E94E98D65A8@R-project.org>
 <CAERMt4doKk0OFujPOzi7vNz6NrzHV8c56=5=CKMhfWBtyFbY3Q@mail.gmail.com>
 <2e92f0f1-ddfd-1c74-4805-ac65821ccd81@gmail.com>
Message-ID: <25413.5113.302768.190731@stat.math.ethz.ch>

>>>>> Ben Bolker 
>>>>>     on Mon, 10 Oct 2022 16:59:35 -0400 writes:

    > Right now as.POSIXlt.Date() is just
    > function (x, ...)
    > .Internal(Date2POSIXlt(x))

It has been quite a bit different in R-devel  for a little
while.  NEWS entries  (there are more already, and more coming
on the wide topic)

    * The as.POSIXlt(<POSIXlt>) and as.POSIXct(<POSIXct>) default
      methods now do obey their tz argument, also in this case.

    * as.POSIXlt(<Date>) now does apply a tz (timezone) argument, as
      does as.POSIXct(); partly suggested by Roland Fuss on the R-devel
      mailing list.

and indeed it would have been good had you used (and read) the
R-devel mailing list  which is much more appropriate on the
topic of *changing* base R behavior.




    > How expensive would it be to throw a warning when '...' is provided by 
    > the user/discarded ??

    > Alternately, perhaps the documentation could be amended, although I'm 
    > not quite sure what to suggest. (The sentence Liam refers to, "Dates 
    > without times are treated as being at midnight UTC." is correct but 
    > terse ...)


    > On 2022-10-10 4:50 p.m., Alexandre Courtiol wrote:
    >> Hi Simon,
    >> 
    >> Thanks for the clarification.
    >> 
    >> From a naive developer point of view, we were initially baffled that the
    >> generic as.POSIXlt() does very different things on a character and on a
    >> Date input:
    >> 
    >> as.POSIXlt(as.character(foo), "Europe/Berlin")
    >> [1] "1992-09-27 CEST"
    >> 
    >> as.POSIXlt(foo, "Europe/Berlin")
    >> [1] "1992-09-27 UTC"
    >> 
    >> Based on what you said, it does make sense: it is only when creating the
    >> date/time that we want to include the time zone and that only happens when
    >> we don't already work on a previously created date.
    >> That is your subtle but spot-on distinction between "parsing" and
    >> "changing" the time zone.
    >> 
    >> Yet, we do find it dangerous that as.POSIXlt.Date() accepts a time zone but
    >> does nothing of it, especially when the help file starts with:
    >> 
    >> Usage
    >> as.POSIXlt(x, tz = "", ...)
    >> 
    >> The behaviour is documented, as Liam reported it, but still, we will almost
    >> certainly not be the last one tripping on this (without even adding the
    >> additional issue of as.POSIXct() behaving differently across OS).
    >> 
    >> Thanks again,
    >> 
    >> Alex & Liam
    >> 
    >> 
    >> 
    >> 
    >> On Mon, 10 Oct 2022 at 22:13, Simon Urbanek <simon.urbanek at r-project.org>
    >> wrote:
    >> 
    >>> Liam,
    >>> 
    >>> I think I have failed to convey my main point in the last e-mail - which
    >>> was that you want to parse the date/time in the timezone that you care
    >>> about so in your example that would be
    >>> 
    >>>> foo <- as.Date(33874, origin = "1899-12-30")
    >>>> foo
    >>> [1] "1992-09-27"
    >>>> as.POSIXlt(as.character(foo), "Europe/Berlin")
    >>> [1] "1992-09-27 CEST"
    >>> 
    >>> I was explicitly saying that you do NOT want to simply change the time
    >>> zone on POSIXlt objects as that won't work for reasons I explained - see my
    >>> last e-mail.
    >>> 
    >>> Cheers,
    >>> Simon
    >>> 
    >>> 
    >>>> On 11/10/2022, at 6:31 AM, Liam Bailey <liam.bailey at liamdbailey.com>
    >>> wrote:
    >>>> 
    >>>> Hi all,
    >>>> 
    >>>> Thanks Simon for the detailed response, that helps us understand a lot
    >>> better what?s going on! However, with your response in mind, we still
    >>> encounter some behaviour that we did not expect.
    >>>> 
    >>>> I?ve included another minimum reproducible example below to expand on
    >>> the situation. In this example, `foo` is a Date object that we generate
    >>> from a numeric input. Following your advice, `bar` is then a POSIXlt object
    >>> where we now explicitly define timezone using argument tz. However, even
    >>> though we are explicit about the timezone the POSIXlt that is generated is
    >>> always in UTC. This then leads to the issues outlined by Alexandre above,
    >>> which we now understand are caused by DST.
    >>>> 
    >>>> ``` r
    >>>> #Generate date from numeric
    >>>> #Not possible to specify tz at this point
    >>>> foo <- as.Date(33874, origin = "1899-12-30")
    >>>> dput(foo)
    >>>> #> structure(8305, class = "Date")
    >>>> 
    >>>> #Convert to POSIXlt specifying UTC timezone
    >>>> bar <- as.POSIXlt(foo, tz = "UTC")
    >>>> dput(bar)
    >>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
    >>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
    >>> c("POSIXlt",
    >>>> #> "POSIXt"), tzone = "UTC")
    >>>> 
    >>>> #Convert to POSIXlt specifying Europe/Berlin.
    >>>> #Time zone is still UTC
    >>>> bar <- as.POSIXlt(foo, tz = "Europe/Berlin")
    >>>> dput(bar)
    >>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
    >>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
    >>> c("POSIXlt",
    >>>> #> "POSIXt"), tzone = "UTC")
    >>>> ```
    >>>> 
    >>>> 
    >>>> We noticed that this occurs because the tz argument is not passed to
    >>> `.Internal(Date2POSIXlt())` inside `as.POSIXlt.Date()`.
    >>>> 
    >>>> Reading through the documentation for `as.POSIX*` we can see that this
    >>> behaviour is described:
    >>>> 
    >>>> > ?Dates without times are treated as being at midnight UTC.?
    >>>> 
    >>>> In this case, if we want to convert a Date object to POSIX* and specify
    >>> a (non-UTC) timezone would the best strategy be to first coerce our Date
    >>> object to character? Alternatively, `lubridate::as_datetime()` does seem to
    >>> recognise the tz argument and convert a Date object to POSIX* with non-UTC
    >>> time zone (see second example below). But it would be nice to know if there
    >>> are subtle differences between these two approaches that we should be aware
    >>> of.
    >>>> 
    >>>> ``` r
    >>>> foo <- as.Date(33874, origin = "1899-12-30")
    >>>> dput(foo)
    >>>> #> structure(8305, class = "Date")
    >>>> 
    >>>> #Convert to POSIXct specifying UTC timezone
    >>>> bar <- lubridate::as_datetime(foo, tz = "UTC")
    >>>> dput(as.POSIXlt(bar))
    >>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
    >>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 0L), class =
    >>> c("POSIXlt",
    >>>> #> "POSIXt"), tzone = "UTC")
    >>>> 
    >>>> #Convert to POSIXct specifying Europe/Berlin
    >>>> bar <- lubridate::as_datetime(foo, tz = "Europe/Berlin")
    >>>> dput(as.POSIXlt(bar))
    >>>> #> structure(list(sec = 0, min = 0L, hour = 0L, mday = 27L, mon = 8L,
    >>>> #>     year = 92L, wday = 0L, yday = 270L, isdst = 1L, zone = "CEST",
    >>>> #>     gmtoff = 7200L), class = c("POSIXlt", "POSIXt"), tzone =
    >>> c("Europe/Berlin",
    >>>> #> "CET", "CEST"))
    >>>> ```
    >>>> 
    >>>> Thanks again for all your help.
    >>>> Alex & Liam
    >>>> 
    >>>>> On 10 Oct 2022, at 6:40 pm, Hadley Wickham <h.wickham at gmail.com> wrote:
    >>>>> 
    >>>>> On Sun, Oct 9, 2022 at 9:31 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
    >>> wrote:
    >>>>>> 
>>>>> ... which is why tidyverse functions and Python datetime handling irk
    >>> me so much.
    >>>>>> 
>>>>> Is tidyverse time handling intrinsically broken? They have a standard
    >>> practice of reading time as UTC and then using force_tz to fix the
    >>> "mistake". Same as Python.
    >>>>> 
    >>>>> Can you point to any docs that lead you to this conclusion so we can
    >>>>> get them fixed? I strongly encourage people to parse date-times in the
    >>>>> correct time zone; this is why lubridate::ymd_hms() and friends have a
    >>>>> tz argument.
    >>>>> 
    >>>>> Hadley
    >>>>> 
    >>>>> --
    >>>>> http://hadley.nz
    >>>> 
    >>> 
    >>> 
    >> 

    > -- 
    > Dr. Benjamin Bolker
    > Professor, Mathematics & Statistics and Biology, McMaster University
    > Director, School of Computational Science and Engineering
    > (Acting) Graduate chair, Mathematics & Statistics
    >> E-mail is sent at my convenience; I don't expect replies outside of 
    > working hours.

    > ______________________________________________
    > R-package-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-package-devel


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Oct 11 09:38:35 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 11 Oct 2022 10:38:35 +0300
Subject: [R-pkg-devel] Identify Original Column Names of Model Matrix
In-Reply-To: <SY2PR01MB30033EFCF280CCC2EB45B06DCD209@SY2PR01MB3003.ausprd01.prod.outlook.com>
References: <SY2PR01MB30033EFCF280CCC2EB45B06DCD209@SY2PR01MB3003.ausprd01.prod.outlook.com>
Message-ID: <20221011103835.0a003d6d@Tarkus>

On Mon, 10 Oct 2022 08:00:04 +0000
Dario Strbenac <dstr7320 at uni.sydney.edu.au> wrote:

> It requires input data to be in one-hot encoding, which is created by
> Matrix::sparse.model.matrix. For further analysis, such as variable
> importance, is there a way to identify which original feature each
> column of a sparse.model.matrix result was derived from?

?Matrix::sparse.model.matrix seems to recommend
MatrixModel::model.Matrix for this reason. The latter function returns
an object with additional slots `assign` and `contrasts`, which should
make it possible to recover the original columns.

-- 
Best regards,
Ivan


From Qu|r|n_St|er @end|ng |rom gmx@de  Tue Oct 11 09:35:10 2022
From: Qu|r|n_St|er @end|ng |rom gmx@de (Quirin Stier)
Date: Tue, 11 Oct 2022 09:35:10 +0200
Subject: [R-pkg-devel] R package development using GPU based on R package
 OpenCL
Message-ID: <570b824b-c239-aa61-c0e2-5a553ebf91ae@gmx.de>

Dear members,

I have difficulties packing my OpenCL functions together as a complete R
package. I did not find any exemplary R package building upon the R
OpenCL Package. Currently I can only run the OpenCL functions as was
presented by the OpenCL examples of the OpenCL package itself. So,
assuming I have working OpenCL files, how can I create the MakeVars (or
whatever necessity needs to be done), in order to create a fully
functional R package?

Best regards,

Quirin


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Tue Oct 11 18:16:03 2022
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Tue, 11 Oct 2022 16:16:03 +0000
Subject: [R-pkg-devel] 
 R package development using GPU based on R package OpenCL
In-Reply-To: <570b824b-c239-aa61-c0e2-5a553ebf91ae@gmx.de>
References: <570b824b-c239-aa61-c0e2-5a553ebf91ae@gmx.de>
Message-ID: <BY5PR04MB6627ECE1F2AFE9B7C331E49EF9239@BY5PR04MB6627.namprd04.prod.outlook.com>

I?m not particularly experienced with this but wrote a ?proof-of-concept? skeleton of a package at https://github.com/mtmorgan/ocl . The basics are


  *   Import OpenCL in the DESCRIPTION file
  *   Write OpenCL scripts in inst/ (dnorm implemented in OpenCL)
  *   Use the helper function in R/ocl.R to source the code
  *   Provide a user-friendly interface as in R/examples.R (dnorm_ocl)

Martin

From: R-package-devel <r-package-devel-bounces at r-project.org> on behalf of Quirin Stier <Quirin_Stier at gmx.de>
Date: Tuesday, October 11, 2022 at 10:46 AM
To: r-package-devel at r-project.org <r-package-devel at r-project.org>
Subject: [R-pkg-devel] R package development using GPU based on R package OpenCL
Dear members,

I have difficulties packing my OpenCL functions together as a complete R
package. I did not find any exemplary R package building upon the R
OpenCL Package. Currently I can only run the OpenCL functions as was
presented by the OpenCL examples of the OpenCL package itself. So,
assuming I have working OpenCL files, how can I create the MakeVars (or
whatever necessity needs to be done), in order to create a fully
functional R package?

Best regards,

Quirin

______________________________________________
R-package-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-package-devel

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Oct 12 23:36:05 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 13 Oct 2022 10:36:05 +1300
Subject: [R-pkg-devel] Guidance on splitting up an R package?
In-Reply-To: <CALnEB17ExKcv=+EH4NycFFta+jaF0N1FjbfCphttK=cnBdKgow@mail.gmail.com>
References: <CALnEB17ExKcv=+EH4NycFFta+jaF0N1FjbfCphttK=cnBdKgow@mail.gmail.com>
Message-ID: <20221013103605.6244b4ff@rolf-Latitude-E7470>


On Tue, 4 Oct 2022 16:46:03 +0200
Vincent van Hees <vincentvanhees at gmail.com> wrote:

> Dear all,
> 
> I am looking for guidance (blog posts / books / people with
> expertise) on how to split up an R package that has grown a lot in
> complexity and size. To make it worthwhile, the split needs to ease
> the maintenance and ongoing development.

<SNIP>

Here is some advice based on our experience in splitting the
'spatstat' package (over 170,000 lines of code, now split into 10
sub-packages, which took us about one person-year of work).

See https://github.com/spatstat/spatstat.

1. Don't split your package unless you must.

Splitting a package into sub-packages takes considerable effort.
Maintaining a set of sub-packages requires much more effort than
maintaining a single large package.  We estimate, quasi-seriously,
that the amount of effort required is O(n^2) where n is the number
of sub-packages.  :-)

If you split a package, the CRAN servers will have less work, but
almost everyone else --- developers, maintainers, CRAN team, users
--- will have more work.  You won't even reduce the number of emails
from CRAN: the R package checker complains when a package is large,
but it also complains when the package Depends on many sub-packages.

2. Design the split.

Do not start tinkering until you have a plan.  Print out a list
of the functions (or the R files and help files) in your package,
and think about a simple rule for splitting/grouping them.

The rule for splitting the package needs to be simple and easy
to apply for developers and users.  For example in spatstat we
separated 'exploratory' statistical summaries from 'parametric'
statistical models because we can all remember what that means.
(Note that *users* have to ?apply? the splitting rule in order
to know where to find/look for a particular function after the
package has been split.)

A good splitting rule is something to do with the fundamental purpose
of each function.  The amount of trouble you will have after the
split is related to the number of dependencies (between functions)
that cross these boundaries, and the easiest way to minimise this
is to group the functions according to their fundamental purpose.

Give plenty of notice to the maintainers of packages that depend
on your package.

3. Use 'make' and 'filepp' to implement the split.

Leave the original source files where they are.  Maintain the
original source files as the master copies (i.e. bug fixes are
fixed in these original files).

For each sub-package, set up a new folder/directory with a Makefile
that copies selected source files from the original package into
the new directory.  The Makefile can include rules that invoke
'filepp' to filter the source files. Arguments to the 'filepp' call
can specify the names of variables that will then be substituted
into the source code, or used as variables in 'if/then' directives
to switch on/off blocks of code.  This setup makes it much easier
to keep track of the fate of each file, and to change your mind
if needed.

The "make" tool is extremely powerful and useful, and is ubiquitously
applied by software developers.  However its syntax is not perspicuous,
and can be daunting until you become experienced.  If you are not
completely comfortable with "make" you might find the tutorials at

    https://makefiletutorial.com

and

    https://cs.colby.edu/maxwell/courses/tutorials/maketutor

to be helpful.

For information on filepp see https://www-users.york.ac.uk/~dm26/filepp

4. Do the split offline.

Develop the sub-packages on your own machine until they all pass
the package checker.

5.  Consider the sequence of steps to get the packages on CRAN.

CRAN has no mechanism for submitting a set of packages at the
same time.  Each submission is checked individually, on several
different servers, using several versions of R, using the packages
that are installed on that server.  Hence the submission of your new
sub-packages must be carried out according to a carefully considered
incremental process.

Problems that can occur include:

a. Incompatibility between your new submission and the packages
currently on the particular  server.

b. Cycles (loops) in the dependence graph.  The dependence between
functions in the packages may include loops where A depends on B
which depends on C which depends on A, etc.

c. Hard crashes.  Crashes can occur if you use compiled functions
(e.g. C language) or if your package is byte-compiled.  In either
case, changes to the interface (argument sequence) of compiled or
byte-compiled code in one sub-package can result in an error or
hard crash when another sub-package tries to call a function using
the wrong interface.

There is no sure way to prevent these happening.  The best defence
is to use the version number dependency rules in the DESCRIPTION
file (to prevent the use of incompatible packages), and to allow
about a week for each submitted package to propagate through the
CRAN testing network (to ensure that the latest versions are used).

Despite this, you can expect to have correspondence with CRAN about
such problems.

Allow plenty of time between submitting successive sub-packages.
Give plenty of notice to users and maintainers of dependent packages.

Hope this helps.

cheers,

Rolf Turner (on behalf of Adrian Baddeley and Ege Rubak)

P.S.  I hope that this posting is not too late to be useful.  The
lateness is entirely the fault of Rolf Turner.

R.T.


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Thu Oct 13 03:16:20 2022
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Wed, 12 Oct 2022 20:16:20 -0500
Subject: [R-pkg-devel] =?utf-8?q?Problems_with_news_in_=E2=80=98NEWS?=
 =?utf-8?b?4oCZ?=
In-Reply-To: <20221013005510.eff91cf747f7bc84@rhub.io>
References: <20221013005510.eff91cf747f7bc84@rhub.io>
Message-ID: <f1198681-8078-8b40-3aa2-63bec1066b73@effectivedefense.org>

Hello, All:


	  devtools::check_rhub("Ecdat") complained:


Problems with news in ?NEWS?:
    Cannot process chunk/lines:
      2022-10-12:
    Cannot process chunk/lines:
      Ecdat 0.4-2 updated "terrorism" to 2020.
...


	  For more see below.  This is with the current version of


https://github.com/sbgraves237/Ecdat


	  I copied NEWS to NEWS.md and tried to format it as described in:


https://r-pkgs.org/other-markdown.html#news


	  Sadly, I still get the same error.  It seems to be ignoring my 
NEWS.md file and continuing to tell me I haven't fixed NEWS.


	  What do you suggest?
	  Thanks,
	  Spencer Graves


-------- Forwarded Message --------
Subject: 	Ecdat 0.4-2: NOTE
Date: 	Thu, 13 Oct 2022 00:55:10 +0000
From: 	R-hub builder <support at rhub.io>
To: 	spencer.graves at effectivedefense.org



Ecdat 0.4-2: NOTE
	
Ecdat 0.4-2: NOTE
*Build ID:* 	|Ecdat_0.4-2.tar.gz-aec6a2cb4b8a43cfbab0405f54e67c64|
*Platform:* 	Windows Server 2022, R-devel, 64 bit
*Submitted:* 	5 minutes 25 seconds ago
*Build time:* 	5 minutes 16.2 seconds


       NOTES:

* checking package subdirectories ... NOTE
Problems with news in 'NEWS':
    Cannot process chunk/lines:
      2022-10-12:
    Cannot process chunk/lines:
      Ecdat 0.4-2 updated "terrorism" to 2020.
    Cannot process chunk/lines:
      2022-07-01:
    Cannot process chunk/lines:
      Ecdat 0.4-1 replaced non-breaking spaces that used Latin-1 
encoding with " " in 4 "demoFiles/NIPA6.16*.csv" files, because the said 
non-breaking spaces were not valid in UTF-8 and were rejected by a 
development version of R.
      2022-06-14:
    Cannot process chunk/lines:
      Ecdat 0.4-0 adds new datasets USnewspapers and USPS (US Postal 
Service) while adding federal government budget data to USGDPpresidents.
    Cannot process chunk/lines:
      2020-11-01:
    Cannot process chunk/lines:
      Ecdat 0.3-9 deletes ~demoFiles/*_data.xls, because they were used 
to test Ecfun::financialDataFiles and Ecfun::readFinancialDataFiles, and 
those two functions were removed, because they used gdata, which was not 
being maintained, and the work required to maintain them exceeded the 
current need of the maintainer.
    Cannot process chunk/lines:
      2020-02-08:  Ecdat 0.3-6 adds variables popM, popYr, GDP_B, and 
GDPyr to data set "nuclearWeaponStates".
    Cannot process chunk/lines:
      2019-12-05:  Ecdat 0.3-5 corrects the description of Crime$density 
to read, "hundreds of people per square mile" from "people per square 
mile".  Thanks to Yungfong "Frank" Tang for identifying this error and 
confirming the needed correction.
    Cannot process chunk/lines:
      2019-11-05:  Ecdat 0.3-4 adds variable 'firstTestYr' to 
'nuclearWeaponStates'.  It also corrects an error in the 'Mroz' data 
set, in that "work" had the names of the levels incorrectly swapped.
    Cannot process chunk/lines:
      Ecdat 0.3-3 adds data set "nuclearWeaponStates", which might be 
used to model the probability distribution of the time to the next new 
nuclear weapon state.
    Cannot process chunk/lines:

* checking for detritus in the temp directory ... NOTE
Found the following files/directories:
    'lastMiKTeXException'

See the full build log: HTML 
<https://builder.r-hub.io/status/Ecdat_0.4-2.tar.gz-aec6a2cb4b8a43cfbab0405f54e67c64>, 
text 
<https://builder.r-hub.io/status/original/Ecdat_0.4-2.tar.gz-aec6a2cb4b8a43cfbab0405f54e67c64>, 
artifacts 
<https://artifacts.r-hub.io/Ecdat_0.4-2.tar.gz-aec6a2cb4b8a43cfbab0405f54e67c64>. 

Have questions, suggestions or want to report a bug? Please file an 
issue ticket at GitHub <https://github.com/r-hub/rhub/issues>. Thank You 
for using the R-hub builder.

(c) 2016 The R Consortium


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Oct 13 11:34:19 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 13 Oct 2022 12:34:19 +0300
Subject: [R-pkg-devel] =?utf-8?q?Problems_with_news_in_=E2=80=98NEWS?=
 =?utf-8?b?4oCZ?=
In-Reply-To: <f1198681-8078-8b40-3aa2-63bec1066b73@effectivedefense.org>
References: <20221013005510.eff91cf747f7bc84@rhub.io>
 <f1198681-8078-8b40-3aa2-63bec1066b73@effectivedefense.org>
Message-ID: <20221013123419.4affc14e@arachnoid>

? Wed, 12 Oct 2022 20:16:20 -0500
Spencer Graves <spencer.graves at effectivedefense.org> ?????:

> I copied NEWS to NEWS.md and tried to format it as described in:
> 
> 
> https://r-pkgs.org/other-markdown.html#news
> 
> 
> 	  Sadly, I still get the same error.  It seems to be ignoring
> my NEWS.md file and continuing to tell me I haven't fixed NEWS.

Does it help to remove the NEWS after you've created NEWS.md in the
root directory of your package? In theory, NEWS.md takes precedence
over everything except inst/NEWS.Rd, but maybe that's not the case when
checking the package.

For the record, both the plain text format R expects in the NEWS file
and the Markdown format for NEWS.md are described in help(news).

-- 
Best regards,
Ivan


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Thu Oct 13 17:29:28 2022
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Thu, 13 Oct 2022 10:29:28 -0500
Subject: [R-pkg-devel] =?utf-8?q?Problems_with_news_in_=E2=80=98NEWS?=
 =?utf-8?b?4oCZ?=
In-Reply-To: <20221013123419.4affc14e@arachnoid>
References: <20221013005510.eff91cf747f7bc84@rhub.io>
 <f1198681-8078-8b40-3aa2-63bec1066b73@effectivedefense.org>
 <20221013123419.4affc14e@arachnoid>
Message-ID: <c5102970-e410-8e61-c1a5-7981b9a83393@effectivedefense.org>



On 10/13/22 4:34 AM, Ivan Krylov wrote:
> ? Wed, 12 Oct 2022 20:16:20 -0500
> Spencer Graves <spencer.graves at effectivedefense.org> ?????:
> 
>> I copied NEWS to NEWS.md and tried to format it as described in:
>>
>>
>> https://r-pkgs.org/other-markdown.html#news
>>
>>
>> 	  Sadly, I still get the same error.  It seems to be ignoring
>> my NEWS.md file and continuing to tell me I haven't fixed NEWS.
> 
> Does it help to remove the NEWS after you've created NEWS.md in the
> root directory of your package? In theory, NEWS.md takes precedence
> over everything except inst/NEWS.Rd, but maybe that's not the case when
> checking the package.


Thanks.  I did that, and it worked.

> 
> For the record, both the plain text format R expects in the NEWS file
> and the Markdown format for NEWS.md are described in help(news).
> 

Thanks, I missed that reference but managed to find something that worked.


	  Spencer


